{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 conv_dw_1\n",
      "6 conv_dw_1_bn\n",
      "7 conv_dw_1_relu\n",
      "8 conv_pw_1\n",
      "9 conv_pw_1_bn\n",
      "10 conv_pw_1_relu\n",
      "11 conv_pad_2\n",
      "12 conv_dw_2\n",
      "13 conv_dw_2_bn\n",
      "14 conv_dw_2_relu\n",
      "15 conv_pw_2\n",
      "16 conv_pw_2_bn\n",
      "17 conv_pw_2_relu\n",
      "18 conv_dw_3\n",
      "19 conv_dw_3_bn\n",
      "20 conv_dw_3_relu\n",
      "21 conv_pw_3\n",
      "22 conv_pw_3_bn\n",
      "23 conv_pw_3_relu\n",
      "24 conv_pad_4\n",
      "25 conv_dw_4\n",
      "26 conv_dw_4_bn\n",
      "27 conv_dw_4_relu\n",
      "28 conv_pw_4\n",
      "29 conv_pw_4_bn\n",
      "30 conv_pw_4_relu\n",
      "31 conv_dw_5\n",
      "32 conv_dw_5_bn\n",
      "33 conv_dw_5_relu\n",
      "34 conv_pw_5\n",
      "35 conv_pw_5_bn\n",
      "36 conv_pw_5_relu\n",
      "37 conv_pad_6\n",
      "38 conv_dw_6\n",
      "39 conv_dw_6_bn\n",
      "40 conv_dw_6_relu\n",
      "41 conv_pw_6\n",
      "42 conv_pw_6_bn\n",
      "43 conv_pw_6_relu\n",
      "44 conv_dw_7\n",
      "45 conv_dw_7_bn\n",
      "46 conv_dw_7_relu\n",
      "47 conv_pw_7\n",
      "48 conv_pw_7_bn\n",
      "49 conv_pw_7_relu\n",
      "50 conv_dw_8\n",
      "51 conv_dw_8_bn\n",
      "52 conv_dw_8_relu\n",
      "53 conv_pw_8\n",
      "54 conv_pw_8_bn\n",
      "55 conv_pw_8_relu\n",
      "56 conv_dw_9\n",
      "57 conv_dw_9_bn\n",
      "58 conv_dw_9_relu\n",
      "59 conv_pw_9\n",
      "60 conv_pw_9_bn\n",
      "61 conv_pw_9_relu\n",
      "62 conv_dw_10\n",
      "63 conv_dw_10_bn\n",
      "64 conv_dw_10_relu\n",
      "65 conv_pw_10\n",
      "66 conv_pw_10_bn\n",
      "67 conv_pw_10_relu\n",
      "68 conv_dw_11\n",
      "69 conv_dw_11_bn\n",
      "70 conv_dw_11_relu\n",
      "71 conv_pw_11\n",
      "72 conv_pw_11_bn\n",
      "73 conv_pw_11_relu\n",
      "74 conv_pad_12\n",
      "75 conv_dw_12\n",
      "76 conv_dw_12_bn\n",
      "77 conv_dw_12_relu\n",
      "78 conv_pw_12\n",
      "79 conv_pw_12_bn\n",
      "80 conv_pw_12_relu\n",
      "81 conv_dw_13\n",
      "82 conv_dw_13_bn\n",
      "83 conv_dw_13_relu\n",
      "84 conv_pw_13\n",
      "85 conv_pw_13_bn\n",
      "86 conv_pw_13_relu\n",
      "87 global_average_pooling2d_1\n",
      "88 dense_1\n",
      "89 dense_2\n",
      "90 dense_3\n",
      "91 dense_4\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable=False\n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:90]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[90:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "#train_generator=train_datagen.flow_from_directory('Tobacco/train/',\n",
    "#                                                 target_size=(224,224),\n",
    "#                                                 color_mode='rgb',\n",
    "#                                                 batch_size=32,\n",
    "#                                                 class_mode='categorical',\n",
    "#                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2230 images belonging to 10 classes.\n",
      "Found 553 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#    shear_range=0.2,\n",
    "#    zoom_range=0.2,\n",
    "#    horizontal_flip=True,\n",
    "#    validation_split=0.2) # set validation split\n",
    "\n",
    "train_datagen=ImageDataGenerator(validation_split=0.2, \n",
    "    preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "train_data_dir = 'Tobacco/train/'\n",
    "img_height, img_width = 224,224\n",
    "color_mode = 'rgb'\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 36s 515ms/step - loss: 1.5251 - acc: 0.4882 - val_loss: 2.1751 - val_acc: 0.2243\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 28s 413ms/step - loss: 1.0600 - acc: 0.6369 - val_loss: 2.3598 - val_acc: 0.1785\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 29s 417ms/step - loss: 0.9032 - acc: 0.6973 - val_loss: 2.5445 - val_acc: 0.1862\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 26s 373ms/step - loss: 0.8153 - acc: 0.7250 - val_loss: 2.7762 - val_acc: 0.0940\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 28s 403ms/step - loss: 0.7612 - acc: 0.7397 - val_loss: 3.0444 - val_acc: 0.1209\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 29s 421ms/step - loss: 0.6838 - acc: 0.7666 - val_loss: 2.7844 - val_acc: 0.1708\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 25s 366ms/step - loss: 0.6664 - acc: 0.7680 - val_loss: 2.8868 - val_acc: 0.1843\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 27s 388ms/step - loss: 0.6223 - acc: 0.7811 - val_loss: 2.9214 - val_acc: 0.1651\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 30s 428ms/step - loss: 0.5530 - acc: 0.8126 - val_loss: 2.6752 - val_acc: 0.2111\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 29s 414ms/step - loss: 0.5525 - acc: 0.8037 - val_loss: 3.5496 - val_acc: 0.1209\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 368ms/step - loss: 0.4784 - acc: 0.8368 - val_loss: 3.3877 - val_acc: 0.1459\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 27s 390ms/step - loss: 0.4848 - acc: 0.8293 - val_loss: 2.9610 - val_acc: 0.1862\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 27s 392ms/step - loss: 0.4428 - acc: 0.8425 - val_loss: 3.5783 - val_acc: 0.1651\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 26s 379ms/step - loss: 0.4470 - acc: 0.8398 - val_loss: 3.4413 - val_acc: 0.1190\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 27s 388ms/step - loss: 0.4526 - acc: 0.8411 - val_loss: 3.9121 - val_acc: 0.1248\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 26s 378ms/step - loss: 0.3617 - acc: 0.8821 - val_loss: 4.0125 - val_acc: 0.1228\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 26s 375ms/step - loss: 0.3188 - acc: 0.8946 - val_loss: 4.3629 - val_acc: 0.1132\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 29s 425ms/step - loss: 0.3478 - acc: 0.8879 - val_loss: 4.6471 - val_acc: 0.1440\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 26s 374ms/step - loss: 0.3236 - acc: 0.8904 - val_loss: 3.9885 - val_acc: 0.1360\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 27s 387ms/step - loss: 0.3034 - acc: 0.8977 - val_loss: 4.7445 - val_acc: 0.1382\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 25s 360ms/step - loss: 0.2951 - acc: 0.8975 - val_loss: 4.4509 - val_acc: 0.1382\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 28s 411ms/step - loss: 0.2438 - acc: 0.9199 - val_loss: 4.6065 - val_acc: 0.1267\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 26s 383ms/step - loss: 0.2855 - acc: 0.9007 - val_loss: 4.4623 - val_acc: 0.1593\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 27s 385ms/step - loss: 0.2371 - acc: 0.9237 - val_loss: 4.9421 - val_acc: 0.1727\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 27s 385ms/step - loss: 0.2182 - acc: 0.9322 - val_loss: 6.1602 - val_acc: 0.0902\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 28s 409ms/step - loss: 0.2225 - acc: 0.9288 - val_loss: 5.0023 - val_acc: 0.1440\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 28s 403ms/step - loss: 0.2037 - acc: 0.9294 - val_loss: 6.0199 - val_acc: 0.1132\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 26s 379ms/step - loss: 0.1788 - acc: 0.9488 - val_loss: 4.7508 - val_acc: 0.1689\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 25s 356ms/step - loss: 0.1978 - acc: 0.9350 - val_loss: 5.0816 - val_acc: 0.1420\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 25s 366ms/step - loss: 0.1847 - acc: 0.9343 - val_loss: 4.4609 - val_acc: 0.1497\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 30s 429ms/step - loss: 0.1699 - acc: 0.9475 - val_loss: 5.6895 - val_acc: 0.1152\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 26s 380ms/step - loss: 0.1690 - acc: 0.9489 - val_loss: 5.5952 - val_acc: 0.1209\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 27s 394ms/step - loss: 0.1764 - acc: 0.9457 - val_loss: 5.3731 - val_acc: 0.1248\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 24s 344ms/step - loss: 0.1599 - acc: 0.9473 - val_loss: 4.8711 - val_acc: 0.1804\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 29s 415ms/step - loss: 0.1103 - acc: 0.9699 - val_loss: 5.7456 - val_acc: 0.1094\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 27s 389ms/step - loss: 0.1365 - acc: 0.9604 - val_loss: 4.6813 - val_acc: 0.1574\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 27s 394ms/step - loss: 0.1505 - acc: 0.9557 - val_loss: 5.4673 - val_acc: 0.1360\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 25s 361ms/step - loss: 0.1364 - acc: 0.9613 - val_loss: 5.5931 - val_acc: 0.1555\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 25s 356ms/step - loss: 0.1505 - acc: 0.9480 - val_loss: 4.9277 - val_acc: 0.1766\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 26s 383ms/step - loss: 0.1185 - acc: 0.9676 - val_loss: 5.1963 - val_acc: 0.1727\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 26s 378ms/step - loss: 0.1195 - acc: 0.9629 - val_loss: 5.2526 - val_acc: 0.1785\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 25s 366ms/step - loss: 0.1189 - acc: 0.9675 - val_loss: 5.0007 - val_acc: 0.1555\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 26s 383ms/step - loss: 0.0848 - acc: 0.9792 - val_loss: 4.9722 - val_acc: 0.1689\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 26s 379ms/step - loss: 0.1090 - acc: 0.9663 - val_loss: 5.3551 - val_acc: 0.1420\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 26s 373ms/step - loss: 0.0962 - acc: 0.9733 - val_loss: 5.3143 - val_acc: 0.1651\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 28s 405ms/step - loss: 0.1157 - acc: 0.9624 - val_loss: 6.1006 - val_acc: 0.1555\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 24s 350ms/step - loss: 0.1362 - acc: 0.9547 - val_loss: 5.1992 - val_acc: 0.2015\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 29s 424ms/step - loss: 0.0868 - acc: 0.9746 - val_loss: 5.0884 - val_acc: 0.1823\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 25s 368ms/step - loss: 0.1010 - acc: 0.9670 - val_loss: 5.9911 - val_acc: 0.1689\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 27s 389ms/step - loss: 0.0955 - acc: 0.9687 - val_loss: 7.0109 - val_acc: 0.0902\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 26s 374ms/step - loss: 0.0900 - acc: 0.9736 - val_loss: 6.2980 - val_acc: 0.1363\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 24s 352ms/step - loss: 0.0844 - acc: 0.9742 - val_loss: 7.3617 - val_acc: 0.1132\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 31s 443ms/step - loss: 0.0964 - acc: 0.9710 - val_loss: 5.8798 - val_acc: 0.1497\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 26s 375ms/step - loss: 0.0899 - acc: 0.9713 - val_loss: 5.3870 - val_acc: 0.1804\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 26s 374ms/step - loss: 0.0912 - acc: 0.9717 - val_loss: 5.4616 - val_acc: 0.1691\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 26s 371ms/step - loss: 0.0664 - acc: 0.9797 - val_loss: 6.0610 - val_acc: 0.1689\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 26s 379ms/step - loss: 0.0851 - acc: 0.9691 - val_loss: 6.4314 - val_acc: 0.1344\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 25s 370ms/step - loss: 0.0718 - acc: 0.9808 - val_loss: 5.7643 - val_acc: 0.1785\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 28s 405ms/step - loss: 0.0782 - acc: 0.9799 - val_loss: 5.8675 - val_acc: 0.1555\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 26s 370ms/step - loss: 0.0711 - acc: 0.9794 - val_loss: 5.8476 - val_acc: 0.1747\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 28s 408ms/step - loss: 0.0745 - acc: 0.9788 - val_loss: 5.7393 - val_acc: 0.1689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "69/69 [==============================] - 27s 392ms/step - loss: 0.0506 - acc: 0.9887 - val_loss: 7.4401 - val_acc: 0.1152\n",
      "Epoch 63/100\n",
      "69/69 [==============================] - 26s 373ms/step - loss: 0.0468 - acc: 0.9887 - val_loss: 6.8823 - val_acc: 0.1286\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 30s 433ms/step - loss: 0.0480 - acc: 0.9856 - val_loss: 7.2791 - val_acc: 0.1612\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 28s 411ms/step - loss: 0.0736 - acc: 0.9799 - val_loss: 6.8250 - val_acc: 0.2111\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 27s 396ms/step - loss: 0.0836 - acc: 0.9742 - val_loss: 6.3659 - val_acc: 0.1708\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 25s 369ms/step - loss: 0.0372 - acc: 0.9887 - val_loss: 6.7752 - val_acc: 0.1766\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 25s 366ms/step - loss: 0.0832 - acc: 0.9742 - val_loss: 6.3647 - val_acc: 0.1612\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 25s 365ms/step - loss: 0.0912 - acc: 0.9709 - val_loss: 5.4910 - val_acc: 0.1612\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 27s 392ms/step - loss: 0.0694 - acc: 0.9805 - val_loss: 6.1209 - val_acc: 0.1459\n",
      "Epoch 71/100\n",
      "68/69 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9784"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7ffd8198759e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     epochs = nb_epochs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    228\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "#step_size_train=train_generator.n//train_generator.batch_size\n",
    "#model.fit_generator(generator=train_generator,\n",
    "#                   steps_per_epoch=step_size_train,\n",
    "#                   epochs=10, validation_split=0.2)\n",
    "\n",
    "nb_epochs = 100\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
